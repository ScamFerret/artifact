{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5.2: Scam and Legitimate Website Classification Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading python modules\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(predictions, actuals):\n",
    "    if len(predictions) != len(actuals):\n",
    "        raise ValueError(\"The length of predictions and actuals must be the same.\")\n",
    "    \n",
    "    def custom_round(number, digits):\n",
    "        factor = 10 ** digits\n",
    "        return (int(number * factor + 0.5)) / factor\n",
    "    \n",
    "    # Normalize inputs to lower case\n",
    "    predictions = [p.lower() for p in predictions]\n",
    "    actuals = [a.lower() for a in actuals]\n",
    "\n",
    "    true_positive = sum(1 for p, a in zip(predictions, actuals) if p == 'true' and a == 'true')\n",
    "    true_negative = sum(1 for p, a in zip(predictions, actuals) if p == 'false' and a == 'false')\n",
    "    false_positive = sum(1 for p, a in zip(predictions, actuals) if p == 'true' and a == 'false')\n",
    "    false_negative = sum(1 for p, a in zip(predictions, actuals) if p == 'false' and a == 'true')\n",
    "\n",
    "    total = len(predictions)\n",
    "    accuracy = (true_positive + true_negative) / total\n",
    "    tpr = true_positive / (true_positive + false_negative) if (true_positive + false_negative) != 0 else 0\n",
    "    tnr = true_negative / (true_negative + false_positive) if (true_negative + false_positive) != 0 else 0\n",
    "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) != 0 else 0\n",
    "    f1_score = 2 * precision * tpr / (precision + tpr) if (precision + tpr) != 0 else 0\n",
    "\n",
    "    accuracy = custom_round(accuracy, 3)\n",
    "    tpr = custom_round(tpr, 3)\n",
    "    tnr = custom_round(tnr, 3)\n",
    "    precision = custom_round(precision, 3)\n",
    "    f1_score = custom_round(f1_score, 3)\n",
    "\n",
    "    return f\"{accuracy:.3f}\", f\"{tpr:.3f}\", f\"{tnr:.3f}\", f\"{precision:.3f}\", f\"{f1_score:.3f}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_partial_matches(list1, list2):\n",
    "    list1 = [str(x).lower() for x in list1]\n",
    "    list2 = [str(x).lower() for x in list2]\n",
    "    \n",
    "    result = []\n",
    "    for item1 in list1:\n",
    "        is_contained = any(item1 in item2 or item2 in item1 for item2 in list2)\n",
    "        result.append('true' if is_contained else 'false')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Accuracy TPR/Recall TNR Precision F1 score\n",
      "Online Shopping (English) 0.998 0.995 1.000 1.000 0.997\n",
      "Technical Support 0.900 0.800 1.000 1.000 0.889\n",
      "Cryptocurrency 0.888 0.855 0.920 0.914 0.884\n",
      "Investment 0.918 0.835 1.000 1.000 0.910\n",
      "Online Shopping (German) 0.990 0.990 0.990 0.990 0.990\n",
      "Online Shopping (Japanese) 0.980 0.960 1.000 1.000 0.980\n",
      "Total of All Scam Types 0.926 0.871 0.980 0.978 0.921\n",
      "Total of All Languages 0.989 0.982 0.997 0.997 0.989\n"
     ]
    }
   ],
   "source": [
    "# Multi-classification results of GPT-4 evaluation\n",
    "model_type = 'gpt-4'\n",
    "labels = ['true']*200+['false']*200\n",
    "all_scam_types = [[],[]]\n",
    "all_languages = [[],[]]\n",
    "\n",
    "print ('Type', 'Accuracy', 'TPR/Recall', 'TNR', 'Precision', 'F1 score')\n",
    "# Online Shopping (English)\n",
    "check_list = ['fake shopping']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_english/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_english/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results_converted)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "all_languages[0].extend(scam_results_converted)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Online Shopping (English)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Technical Support\n",
    "check_list = ['fake support', 'fake alert', 'fake tech', 'tech support', 'fake security']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/technical_support/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/technical_support/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results_converted)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Technical Support', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Cryptocurrency\n",
    "check_list = ['fake crypto', 'fake investment', 'fake financial']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/cryptocurrency/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/cryptocurrency/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results_converted)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Cryptocurrency', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Investment\n",
    "check_list = ['fake investment', 'fake financial']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/investment/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/investment/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results_converted)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Investment', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Online Shopping (German)\n",
    "check_list = ['fake shopping']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_german/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_german/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_languages[0].extend(scam_results_converted)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Online Shopping (German)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Online Shopping (Japanese)\n",
    "check_list = ['fake shopping']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_japanese/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_japanese/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_languages[0].extend(scam_results_converted)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Online Shopping (Japanese)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "type_labels = ['true']*800+['false']*800\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(all_scam_types[0]+all_scam_types[1], type_labels)\n",
    "print('Total of All Scam Types', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "type_labels = ['true']*600+['false']*600\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(all_languages[0]+all_languages[1], type_labels)\n",
    "print('Total of All Languages', accuracy, tpr, tnr, precision, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Accuracy TPR/Recall TNR Precision F1 score\n",
      "Online Shopping (English) 0.883 0.800 0.965 0.958 0.872\n",
      "Technical Support 0.775 0.570 0.980 0.966 0.717\n",
      "Cryptocurrency 0.810 0.700 0.920 0.897 0.787\n",
      "Investment 0.850 0.710 0.990 0.986 0.826\n",
      "Online Shopping (German) 0.870 0.745 0.995 0.993 0.851\n",
      "Online Shopping (Japanese) 0.875 0.755 0.995 0.993 0.858\n",
      "Total of All Scam Types 0.829 0.695 0.964 0.950 0.803\n",
      "Total of All Languages 0.876 0.767 0.985 0.981 0.861\n"
     ]
    }
   ],
   "source": [
    "# Multi-classification results of GPT-3.5 evaluation\n",
    "model_type = 'gpt-3.5'\n",
    "labels = ['true']*200+['false']*200\n",
    "all_scam_types = [[],[]]\n",
    "all_languages = [[],[]]\n",
    "\n",
    "print ('Type', 'Accuracy', 'TPR/Recall', 'TNR', 'Precision', 'F1 score')\n",
    "# Online Shopping (English)\n",
    "check_list = ['fake shopping']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_english/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_english/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results_converted)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "all_languages[0].extend(scam_results_converted)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Online Shopping (English)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Technical Support\n",
    "check_list = ['fake support', 'fake alert', 'fake tech', 'tech support', 'fake security']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/technical_support/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/technical_support/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results_converted)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Technical Support', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Cryptocurrency\n",
    "check_list = ['fake crypto', 'fake investment', 'fake financial']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/cryptocurrency/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/cryptocurrency/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results_converted)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Cryptocurrency', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Investment\n",
    "check_list = ['fake investment', 'fake financial']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/investment/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/investment/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results_converted)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Investment', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Online Shopping (German)\n",
    "check_list = ['fake shopping']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_german/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_german/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_languages[0].extend(scam_results_converted)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Online Shopping (German)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Online Shopping (Japanese)\n",
    "check_list = ['fake shopping']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_japanese/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_japanese/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_languages[0].extend(scam_results_converted)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Online Shopping (Japanese)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "type_labels = ['true']*800+['false']*800\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(all_scam_types[0]+all_scam_types[1], type_labels)\n",
    "print('Total of All Scam Types', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "type_labels = ['true']*600+['false']*600\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(all_languages[0]+all_languages[1], type_labels)\n",
    "print('Total of All Languages', accuracy, tpr, tnr, precision, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Accuracy TPR/Recall TNR Precision F1 score\n",
      "Online Shopping (English) 0.863 0.805 0.920 0.910 0.854\n",
      "Technical Support 0.545 0.145 0.945 0.725 0.242\n",
      "Cryptocurrency 0.835 0.785 0.885 0.872 0.826\n",
      "Investment 0.480 0.005 0.955 0.100 0.010\n",
      "Online Shopping (German) 0.868 0.795 0.940 0.930 0.857\n",
      "Online Shopping (Japanese) 0.930 0.890 0.970 0.967 0.927\n",
      "Total of All Scam Types 0.681 0.435 0.926 0.855 0.577\n",
      "Total of All Languages 0.887 0.830 0.943 0.936 0.880\n"
     ]
    }
   ],
   "source": [
    "# Multi-class classification results of Gemini Pro evaluation\n",
    "model_type = 'geminipro'\n",
    "labels = ['true']*200+['false']*200\n",
    "all_scam_types = [[],[]]\n",
    "all_languages = [[],[]]\n",
    "\n",
    "print ('Type', 'Accuracy', 'TPR/Recall', 'TNR', 'Precision', 'F1 score')\n",
    "# Online Shopping (English)\n",
    "check_list = ['fake shopping']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_english/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_english/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results_converted)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "all_languages[0].extend(scam_results_converted)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Online Shopping (English)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Technical Support\n",
    "check_list = ['fake support', 'fake alert', 'fake tech', 'tech support', 'fake security']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/technical_support/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/technical_support/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results_converted)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Technical Support', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Cryptocurrency\n",
    "check_list = ['fake crypto', 'fake investment', 'fake financial']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/cryptocurrency/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/cryptocurrency/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results_converted)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Cryptocurrency', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Investment\n",
    "check_list = ['fake investment', 'fake financial']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/investment/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/investment/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results_converted)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Investment', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Online Shopping (German)\n",
    "check_list = ['fake shopping']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_german/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_german/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_languages[0].extend(scam_results_converted)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Online Shopping (German)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Online Shopping (Japanese)\n",
    "check_list = ['fake shopping']\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_japanese/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    if 'scam_type' not in data[-1]['observation']:\n",
    "        scam_results.append(\"None\")\n",
    "        continue\n",
    "    scam_results.append(data[-1]['observation']['scam_type'])\n",
    "scam_results_converted = check_partial_matches(scam_results, check_list)\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_japanese/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_languages[0].extend(scam_results_converted)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results_converted+legitimate_results, labels)\n",
    "print('Online Shopping (Japanese)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "type_labels = ['true']*800+['false']*800\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(all_scam_types[0]+all_scam_types[1], type_labels)\n",
    "print('Total of All Scam Types', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "type_labels = ['true']*600+['false']*600\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(all_languages[0]+all_languages[1], type_labels)\n",
    "print('Total of All Languages', accuracy, tpr, tnr, precision, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Accuracy TPR/Recall TNR Precision F1 score\n",
      "Online Shopping (English) 0.993 0.985 1.000 1.000 0.992\n",
      "Technical Support 0.975 0.950 1.000 1.000 0.974\n",
      "Cryptocurrency 0.925 0.930 0.920 0.921 0.925\n",
      "Investment 0.995 0.990 1.000 1.000 0.995\n",
      "Online Shopping (German) 0.990 0.990 0.990 0.990 0.990\n",
      "Online Shopping (Japanese) 0.995 0.990 1.000 1.000 0.995\n",
      "Total of All Scam Types 0.972 0.964 0.980 0.980 0.972\n",
      "Total of All Languages 0.993 0.988 0.997 0.997 0.992\n"
     ]
    }
   ],
   "source": [
    "# Binary classification results of GPT-4 evaluation\n",
    "model_type = 'gpt-4'\n",
    "labels = ['true']*200+['false']*200\n",
    "all_scam_types = [[],[]]\n",
    "all_languages = [[],[]]\n",
    "\n",
    "print ('Type', 'Accuracy', 'TPR/Recall', 'TNR', 'Precision', 'F1 score')\n",
    "# Online Shopping (English)\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_english/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_english/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "all_languages[0].extend(scam_results)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Online Shopping (English)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Technical Support\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/technical_support/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/technical_support/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Technical Support', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Cryptocurrency\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/cryptocurrency/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/cryptocurrency/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Cryptocurrency', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Investment\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/investment/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/investment/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Investment', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Online Shopping (German)\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_german/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_german/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_languages[0].extend(scam_results)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Online Shopping (German)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Online Shopping (Japanese)\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_japanese/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_japanese/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_languages[0].extend(scam_results)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1= calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Online Shopping (Japanese)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "type_labels = ['true']*800+['false']*800\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(all_scam_types[0]+all_scam_types[1], type_labels)\n",
    "print('Total of All Scam Types', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "type_labels = ['true']*600+['false']*600\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(all_languages[0]+all_languages[1], type_labels)\n",
    "print('Total of All Languages', accuracy, tpr, tnr, precision, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Accuracy TPR/Recall TNR Precision F1 score\n",
      "Online Shopping (English) 0.923 0.880 0.965 0.962 0.919\n",
      "Technical Support 0.950 0.920 0.980 0.979 0.948\n",
      "Cryptocurrency 0.925 0.930 0.920 0.921 0.925\n",
      "Investment 0.955 0.920 0.990 0.989 0.953\n",
      "Online Shopping (German) 0.903 0.810 0.995 0.994 0.893\n",
      "Online Shopping (Japanese) 0.960 0.925 0.995 0.995 0.959\n",
      "Total of All Scam Types 0.938 0.913 0.964 0.962 0.936\n",
      "Total of All Languages 0.928 0.872 0.985 0.983 0.924\n"
     ]
    }
   ],
   "source": [
    "# Binary Classification results of GPT-3.5 evaluation\n",
    "model_type = 'gpt-3.5'\n",
    "labels = ['true']*200+['false']*200\n",
    "all_scam_types = [[],[]]\n",
    "all_languages = [[],[]]\n",
    "\n",
    "print ('Type', 'Accuracy', 'TPR/Recall', 'TNR', 'Precision', 'F1 score')\n",
    "# Online Shopping (English)\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_english/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_english/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "all_languages[0].extend(scam_results)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Online Shopping (English)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Technical Support\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/technical_support/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/technical_support/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Technical Support', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Cryptocurrency\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/cryptocurrency/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/cryptocurrency/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Cryptocurrency', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Investment\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/investment/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/investment/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Investment', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Online Shopping (German)\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_german/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_german/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_languages[0].extend(scam_results)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Online Shopping (German)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Online Shopping (Japanese)\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_japanese/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_japanese/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_languages[0].extend(scam_results)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1= calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Online Shopping (Japanese)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "type_labels = ['true']*800+['false']*800\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(all_scam_types[0]+all_scam_types[1], type_labels)\n",
    "print('Total of All Scam Types', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "type_labels = ['true']*600+['false']*600\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(all_languages[0]+all_languages[1], type_labels)\n",
    "print('Total of All Languages', accuracy, tpr, tnr, precision, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type Accuracy TPR/Recall TNR Precision F1 score\n",
      "Online Shopping (English) 0.870 0.820 0.920 0.911 0.863\n",
      "Technical Support 0.903 0.860 0.945 0.940 0.898\n",
      "Cryptocurrency 0.843 0.800 0.885 0.874 0.836\n",
      "Investment 0.933 0.910 0.955 0.953 0.931\n",
      "Online Shopping (German) 0.865 0.790 0.940 0.929 0.854\n",
      "Online Shopping (Japanese) 0.940 0.910 0.970 0.968 0.938\n",
      "Total of All Scam Types 0.887 0.848 0.926 0.920 0.882\n",
      "Total of All Languages 0.892 0.840 0.943 0.937 0.886\n"
     ]
    }
   ],
   "source": [
    "# Binary classification results of Gemini Pro evaluation\n",
    "model_type = 'geminipro'\n",
    "labels = ['true']*200+['false']*200\n",
    "all_scam_types = [[],[]]\n",
    "all_languages = [[],[]]\n",
    "\n",
    "print ('Type', 'Accuracy', 'TPR/Recall', 'TNR', 'Precision', 'F1 score')\n",
    "# Online Shopping (English)\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_english/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_english/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "all_languages[0].extend(scam_results)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Online Shopping (English)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Technical Support\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/technical_support/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/technical_support/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Technical Support', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Cryptocurrency\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/cryptocurrency/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/cryptocurrency/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Cryptocurrency', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Investment\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/investment/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/investment/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_scam_types[0].extend(scam_results)\n",
    "all_scam_types[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Investment', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Online Shopping (German)\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_german/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_german/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_languages[0].extend(scam_results)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Online Shopping (German)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "# Online Shopping (Japanese)\n",
    "scam_website_files = glob.glob(f'./{model_type}_results/scam_websites/online_shopping_japanese/*.json')\n",
    "scam_results = list()\n",
    "for path in scam_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    scam_results.append(data[-1]['observation']['result'])\n",
    "legitimate_website_files = glob.glob(f'./{model_type}_results/legitimate_websites/online_shopping_japanese/*.json')\n",
    "legitimate_results = list()\n",
    "for path in legitimate_website_files:\n",
    "    with open(path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    legitimate_results.append(data[-1]['observation']['result'])\n",
    "all_languages[0].extend(scam_results)\n",
    "all_languages[1].extend(legitimate_results)\n",
    "accuracy, tpr, tnr, precision, f1= calculate_metrics(scam_results+legitimate_results, labels)\n",
    "print('Online Shopping (Japanese)', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "type_labels = ['true']*800+['false']*800\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(all_scam_types[0]+all_scam_types[1], type_labels)\n",
    "print('Total of All Scam Types', accuracy, tpr, tnr, precision, f1)\n",
    "\n",
    "type_labels = ['true']*600+['false']*600\n",
    "accuracy, tpr, tnr, precision, f1 = calculate_metrics(all_languages[0]+all_languages[1], type_labels)\n",
    "print('Total of All Languages', accuracy, tpr, tnr, precision, f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
